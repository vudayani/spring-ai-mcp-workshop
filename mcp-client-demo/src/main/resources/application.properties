spring.application.name=mcp-client-demo

# ===================================================================
# LLM Provider Configuration
# ===================================================================
#
# Uncomment the properties for the LLM provider you want to use.
# Make sure you have set the corresponding API key in your environment variables.

# ---------------- OpenAI ----------------
spring.ai.openai.api-key=${OPENAI_API_KEY}
spring.ai.openai.chat.options.model=gpt-4o

# ---------------- Anthropic ----------------
#spring.ai.anthropic.api-key=${SPRING_AI_ANTHROPIC_API_KEY}
#spring.ai.anthropic.chat.options.model=claude-sonnet-4-5-20250929

# MCP servers config
spring.ai.mcp.client.stdio.servers-configuration=classpath:/mcp-servers-config.json

# On-Call Server Connection (Streamable HTTP)
# spring.ai.mcp.client.streamable-http.connections.on-call.url=http://localhost:8081/mcp
